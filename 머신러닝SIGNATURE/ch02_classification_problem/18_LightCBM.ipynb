{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 18 LightGBM\n",
    "[목적]\n",
    "  - XGBoost Model에서 Feature와 Data를 Handling 하여 처리해주는 LightGBM Model 실습 및 해석\n",
    "  - LightGBM의 경우 Missing Value를 Model 자체 내에서 처리해주기 때문에 삭제하지 않아도 됨\n",
    "  - Big Data를 빠르게 학습함\n",
    "  - 논문에서는 데이터 10,000개 이상일 때 사용하라고 했지만, 일단 돌려보자\n",
    "\n",
    "[Process]\n",
    "  1. Define X's & Y\n",
    "  2. Split Train & Valid dataset\n",
    "  3. Modeling\n",
    "  4. Model 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from collections import Counter"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# Data Loading (수술 時 사망 데이터)\n",
    "data_df=pd.read_csv(\"https://raw.githubusercontent.com/GonieAhn/Data-Science-online-course-from-gonie/main/Data%20Store/example_data.csv\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "           censor        event         age        wtkg        hemo  \\\ncount  532.000000   532.000000  532.000000  532.000000  532.000000   \nmean     0.340226   801.236842   35.225564   76.061855    0.078947   \nstd      0.474231   326.887929    8.852094   13.224698    0.269910   \nmin      0.000000    33.000000   13.000000   47.401000    0.000000   \n25%      0.000000   535.750000   29.000000   67.500000    0.000000   \n50%      0.000000   933.500000   34.000000   74.600000    0.000000   \n75%      1.000000  1081.000000   40.000000   83.502000    0.000000   \nmax      1.000000  1231.000000   70.000000  149.000000    1.000000   \n\n             homo       drugs      karnof      oprior         z30  ...  \\\ncount  532.000000  532.000000  532.000000  532.000000  532.000000  ...   \nmean     0.640977    0.118421   95.432331    0.030075    0.546992  ...   \nstd      0.480165    0.323410    5.981856    0.170955    0.498255  ...   \nmin      0.000000    0.000000   70.000000    0.000000    0.000000  ...   \n25%      0.000000    0.000000   90.000000    0.000000    0.000000  ...   \n50%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \n75%      1.000000    0.000000  100.000000    0.000000    1.000000  ...   \nmax      1.000000    1.000000  100.000000    1.000000    1.000000  ...   \n\n           gender        str2       strat     symptom        cd40       cd420  \\\ncount  532.000000  532.000000  532.000000  532.000000  532.000000  532.000000   \nmean     0.812030    0.580827    1.981203    0.167293  353.204887  336.139098   \nstd      0.391056    0.493888    0.905946    0.373589  114.105253  130.961573   \nmin      0.000000    0.000000    1.000000    0.000000  103.000000   49.000000   \n25%      1.000000    0.000000    1.000000    0.000000  271.000000  243.750000   \n50%      1.000000    1.000000    2.000000    0.000000  346.000000  330.500000   \n75%      1.000000    1.000000    3.000000    0.000000  422.000000  418.000000   \nmax      1.000000    1.000000    3.000000    1.000000  771.000000  909.000000   \n\n            cd496           r         cd80        cd820  \ncount  532.000000  532.000000   532.000000   532.000000  \nmean   173.146617    0.603383   987.250000   928.214286  \nstd    191.455406    0.489656   475.223907   438.569798  \nmin     -1.000000    0.000000   221.000000   150.000000  \n25%     -1.000000    0.000000   653.250000   626.500000  \n50%    113.000000    1.000000   881.000000   818.000000  \n75%    324.000000    1.000000  1190.000000  1164.000000  \nmax    857.000000    1.000000  4255.000000  3130.000000  \n\n[8 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>censor</th>\n      <th>event</th>\n      <th>age</th>\n      <th>wtkg</th>\n      <th>hemo</th>\n      <th>homo</th>\n      <th>drugs</th>\n      <th>karnof</th>\n      <th>oprior</th>\n      <th>z30</th>\n      <th>...</th>\n      <th>gender</th>\n      <th>str2</th>\n      <th>strat</th>\n      <th>symptom</th>\n      <th>cd40</th>\n      <th>cd420</th>\n      <th>cd496</th>\n      <th>r</th>\n      <th>cd80</th>\n      <th>cd820</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>...</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n      <td>532.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.340226</td>\n      <td>801.236842</td>\n      <td>35.225564</td>\n      <td>76.061855</td>\n      <td>0.078947</td>\n      <td>0.640977</td>\n      <td>0.118421</td>\n      <td>95.432331</td>\n      <td>0.030075</td>\n      <td>0.546992</td>\n      <td>...</td>\n      <td>0.812030</td>\n      <td>0.580827</td>\n      <td>1.981203</td>\n      <td>0.167293</td>\n      <td>353.204887</td>\n      <td>336.139098</td>\n      <td>173.146617</td>\n      <td>0.603383</td>\n      <td>987.250000</td>\n      <td>928.214286</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.474231</td>\n      <td>326.887929</td>\n      <td>8.852094</td>\n      <td>13.224698</td>\n      <td>0.269910</td>\n      <td>0.480165</td>\n      <td>0.323410</td>\n      <td>5.981856</td>\n      <td>0.170955</td>\n      <td>0.498255</td>\n      <td>...</td>\n      <td>0.391056</td>\n      <td>0.493888</td>\n      <td>0.905946</td>\n      <td>0.373589</td>\n      <td>114.105253</td>\n      <td>130.961573</td>\n      <td>191.455406</td>\n      <td>0.489656</td>\n      <td>475.223907</td>\n      <td>438.569798</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n      <td>33.000000</td>\n      <td>13.000000</td>\n      <td>47.401000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>70.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>103.000000</td>\n      <td>49.000000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>221.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n      <td>535.750000</td>\n      <td>29.000000</td>\n      <td>67.500000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>90.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>271.000000</td>\n      <td>243.750000</td>\n      <td>-1.000000</td>\n      <td>0.000000</td>\n      <td>653.250000</td>\n      <td>626.500000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n      <td>933.500000</td>\n      <td>34.000000</td>\n      <td>74.600000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>2.000000</td>\n      <td>0.000000</td>\n      <td>346.000000</td>\n      <td>330.500000</td>\n      <td>113.000000</td>\n      <td>1.000000</td>\n      <td>881.000000</td>\n      <td>818.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n      <td>1081.000000</td>\n      <td>40.000000</td>\n      <td>83.502000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>100.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>0.000000</td>\n      <td>422.000000</td>\n      <td>418.000000</td>\n      <td>324.000000</td>\n      <td>1.000000</td>\n      <td>1190.000000</td>\n      <td>1164.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n      <td>1231.000000</td>\n      <td>70.000000</td>\n      <td>149.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>100.000000</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>...</td>\n      <td>1.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>1.000000</td>\n      <td>771.000000</td>\n      <td>909.000000</td>\n      <td>857.000000</td>\n      <td>1.000000</td>\n      <td>4255.000000</td>\n      <td>3130.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> Data Shape : (532, 22)\n"
     ]
    }
   ],
   "source": [
    "# Data Quality Checking\n",
    "col = []\n",
    "missing = []\n",
    "level = []\n",
    "for name in data_df.columns:\n",
    "\n",
    "    # Missing\n",
    "    missper = data_df[name].isnull().sum() / data_df.shape[0]\n",
    "    missing.append(round(missper, 4))\n",
    "\n",
    "    # Leveling\n",
    "    lel = data_df[name].dropna()\n",
    "    level.append(len(list(set(lel))))\n",
    "\n",
    "    # Columns\n",
    "    col.append(name)\n",
    "\n",
    "summary = pd.concat([pd.DataFrame(col, columns=['name']),\n",
    "                     pd.DataFrame(missing, columns=['Missing Percentage']),\n",
    "                     pd.DataFrame(level, columns=['Level'])], axis=1)\n",
    "\n",
    "drop_col = summary['name'][(summary['Level'] <= 1) | (summary['Missing Percentage'] >= 0.8)]\n",
    "data_df.drop(columns=drop_col, inplace=True)\n",
    "print(\">>>> Data Shape : {}\".format(data_df.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# X's & Y Split\n",
    "y = data_df['censor']\n",
    "X = data_df.drop(columns=['censor'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>> # of Train data : 372\n",
      ">>>> # of valid data : 160\n",
      ">>>> # of Train data Y : Counter({0: 241, 1: 131})\n",
      ">>>> # of valid data Y : Counter({0: 110, 1: 50})\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2021)\n",
    "print(\">>>> # of Train data : {}\".format(len(train_idx)))\n",
    "print(\">>>> # of valid data : {}\".format(len(valid_idx)))\n",
    "print(\">>>> # of Train data Y : {}\".format(Counter(y.iloc[train_idx])))\n",
    "print(\">>>> # of valid data Y : {}\".format(Counter(y.iloc[valid_idx])))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[LightGBM Parameters]\n",
    "  - Package : https://lightgbm.readthedocs.io/en/latest/Python-Intro.html\n",
    "  - learning_rate : GBM에서 shrinking 하는 것과 같은 것\n",
    "  - reg_lambda : L2 regularization term on weights (analogous to Ridge regression)\n",
    "  - reg_alpha : L1 regularization term on weight (analogous to Lasso regression)\n",
    "  - objective\n",
    "        objective 🔗︎, default = regression, type = enum, options: regression, regression_l1, huber, fair, poisson, quantile, mape, gamma, tweedie, binary, multiclass, multiclassova, cross_entropy, cross_entropy_lambda, lambdarank, rank_xendcg, aliases: objective_type, app, application, loss\n",
    "\n",
    "  - eval_metric [ default according to objective ]\n",
    "    - The metric to be used for validation data.\n",
    "    - The default values are rmse for regression and error for classification.\n",
    "    - Typical values are:\n",
    "        -    rmse – root mean square error\n",
    "        -    mae – mean absolute error\n",
    "        -    logloss – negative log-likelihood\n",
    "        -    error – Binary classification error rate (0.5 threshold)\n",
    "        -    merror – Multiclass classification error rate\n",
    "        -    mlogloss – Multiclass logloss\n",
    "        -    auc: Area under the curve"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[LightGBM]\n",
    "\n",
    "  - Hyperparameter tuning\n",
    "  - n_estimators, learning_rate, max_depth, reg_alpha\n",
    "  - LightGBM은 Hyperparam이 굉장히 많은 알고리즘 중에 하나임\n",
    "  - 위에 4가지만 잘 조정해도 좋은 결과를 얻을 수 있음"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# n_estimators\n",
    "n_tree = [5, 10, 20]\n",
    "# learning_rate\n",
    "l_rate = [0.1, 0.3]\n",
    "# max_depth\n",
    "m_depth = [3, 5]\n",
    "# reg_alpha\n",
    "L1_norm = [0.1, 0.3, 0.5]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Modeling\n",
    "save_n = []\n",
    "save_l = []\n",
    "save_m = []\n",
    "save_L1 = []\n",
    "f1_score_ = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 0 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 55  76]]\n",
      "Train Acc : 0.8413978494623656\n",
      "Train F1-Score : 0.7203791469194314\n",
      "Test Confusion Matrix\n",
      "[[103   7]\n",
      " [ 10  40]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8247422680412372\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 1 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 54  77]]\n",
      "Train Acc : 0.8440860215053764\n",
      "Train F1-Score : 0.7264150943396226\n",
      "Test Confusion Matrix\n",
      "[[102   8]\n",
      " [ 10  40]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.816326530612245\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 2 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 54  77]]\n",
      "Train Acc : 0.8440860215053764\n",
      "Train F1-Score : 0.7264150943396226\n",
      "Test Confusion Matrix\n",
      "[[102   8]\n",
      " [ 10  40]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.816326530612245\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 3 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [ 44  87]]\n",
      "Train Acc : 0.8709677419354839\n",
      "Train F1-Score : 0.7837837837837838\n",
      "Test Confusion Matrix\n",
      "[[101   9]\n",
      " [  9  41]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.82\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 4 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 50  81]]\n",
      "Train Acc : 0.8521505376344086\n",
      "Train F1-Score : 0.7465437788018434\n",
      "Test Confusion Matrix\n",
      "[[101   9]\n",
      " [ 10  40]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8080808080808082\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 5 <<<\n",
      "n_estimators : 5, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [ 44  87]]\n",
      "Train Acc : 0.8682795698924731\n",
      "Train F1-Score : 0.7802690582959643\n",
      "Test Confusion Matrix\n",
      "[[101   9]\n",
      " [  9  41]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.82\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 6 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9166666666666666\n",
      "Train F1-Score : 0.8803088803088803\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.8596491228070174\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 7 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 19 112]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.875\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8672566371681417\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 8 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9193548387096774\n",
      "Train F1-Score : 0.883720930232558\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8672566371681417\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 9 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 20 111]]\n",
      "Train Acc : 0.9220430107526881\n",
      "Train F1-Score : 0.8844621513944223\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8288288288288288\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 10 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.8976377952755905\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.86875\n",
      "Test F1-Score : 0.8108108108108109\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 11 <<<\n",
      "n_estimators : 5, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[231  10]\n",
      " [ 21 110]]\n",
      "Train Acc : 0.9166666666666666\n",
      "Train F1-Score : 0.8764940239043825\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.8545454545454546\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 12 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 36  95]]\n",
      "Train Acc : 0.8817204301075269\n",
      "Train F1-Score : 0.811965811965812\n",
      "Test Confusion Matrix\n",
      "[[98 12]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.851851851851852\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 13 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 36  95]]\n",
      "Train Acc : 0.8817204301075269\n",
      "Train F1-Score : 0.811965811965812\n",
      "Test Confusion Matrix\n",
      "[[98 12]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.9\n",
      "Test F1-Score : 0.851851851851852\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 14 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 33  98]]\n",
      "Train Acc : 0.8897849462365591\n",
      "Train F1-Score : 0.8270042194092826\n",
      "Test Confusion Matrix\n",
      "[[98 12]\n",
      " [ 5 45]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8411214953271027\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 15 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 28 103]]\n",
      "Train Acc : 0.9005376344086021\n",
      "Train F1-Score : 0.8477366255144032\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8440366972477064\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 16 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 25 106]]\n",
      "Train Acc : 0.9112903225806451\n",
      "Train F1-Score : 0.8653061224489796\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8363636363636363\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 17 <<<\n",
      "n_estimators : 10, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 28 103]]\n",
      "Train Acc : 0.9005376344086021\n",
      "Train F1-Score : 0.8477366255144032\n",
      "Test Confusion Matrix\n",
      "[[97 13]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8440366972477064\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 18 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[227  14]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9015151515151515\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 19 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[229  12]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9408602150537635\n",
      "Train F1-Score : 0.9166666666666667\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 20 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[229  12]\n",
      " [ 13 118]]\n",
      "Train Acc : 0.9327956989247311\n",
      "Train F1-Score : 0.9042145593869731\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8376068376068375\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 21 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 12 119]]\n",
      "Train Acc : 0.946236559139785\n",
      "Train F1-Score : 0.9224806201550387\n",
      "Test Confusion Matrix\n",
      "[[98 12]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8623853211009174\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 22 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 10 121]]\n",
      "Train Acc : 0.9543010752688172\n",
      "Train F1-Score : 0.9343629343629344\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8363636363636363\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 23 <<<\n",
      "n_estimators : 10, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [ 11 120]]\n",
      "Train Acc : 0.9516129032258065\n",
      "Train F1-Score : 0.9302325581395349\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8363636363636363\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 24 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[229  12]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9220430107526881\n",
      "Train F1-Score : 0.8871595330739299\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 25 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[229  12]\n",
      " [ 14 117]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 26 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 13 118]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.9007633587786259\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8521739130434782\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 27 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [ 15 116]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9098039215686274\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8392857142857143\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 28 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 14 117]]\n",
      "Train Acc : 0.9381720430107527\n",
      "Train F1-Score : 0.9105058365758756\n",
      "Test Confusion Matrix\n",
      "[[95 15]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8495575221238937\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 29 <<<\n",
      "n_estimators : 20, learning_rate : 0.1, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[232   9]\n",
      " [ 17 114]]\n",
      "Train Acc : 0.9301075268817204\n",
      "Train F1-Score : 0.8976377952755905\n",
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 3 47]]\n",
      "TesT Acc : 0.89375\n",
      "Test F1-Score : 0.8468468468468469\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 30 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[236   5]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9704301075268817\n",
      "Train F1-Score : 0.9578544061302683\n",
      "Test Confusion Matrix\n",
      "[[89 21]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8625\n",
      "Test F1-Score : 0.8166666666666667\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 31 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[233   8]\n",
      " [  6 125]]\n",
      "Train Acc : 0.9623655913978495\n",
      "Train F1-Score : 0.9469696969696969\n",
      "Test Confusion Matrix\n",
      "[[91 19]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.875\n",
      "Test F1-Score : 0.8305084745762712\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 32 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 3, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[234   7]\n",
      " [  8 123]]\n",
      "Train Acc : 0.9596774193548387\n",
      "Train F1-Score : 0.9425287356321839\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8448275862068965\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 33 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.1\n",
      "Train Confusion Matrix\n",
      "[[239   2]\n",
      " [  2 129]]\n",
      "Train Acc : 0.989247311827957\n",
      "Train F1-Score : 0.9847328244274809\n",
      "Test Confusion Matrix\n",
      "[[94 16]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.8875\n",
      "Test F1-Score : 0.8421052631578947\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 34 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.3\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  0 131]]\n",
      "Train Acc : 0.989247311827957\n",
      "Train F1-Score : 0.9849624060150376\n",
      "Test Confusion Matrix\n",
      "[[93 17]\n",
      " [ 2 48]]\n",
      "TesT Acc : 0.88125\n",
      "Test F1-Score : 0.8347826086956522\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n",
      ">>> 35 <<<\n",
      "n_estimators : 20, learning_rate : 0.3, max_depth : 5, reg_alpha : 0.5\n",
      "Train Confusion Matrix\n",
      "[[237   4]\n",
      " [  1 130]]\n",
      "Train Acc : 0.9865591397849462\n",
      "Train F1-Score : 0.9811320754716981\n",
      "Test Confusion Matrix\n",
      "[[92 18]\n",
      " [ 4 46]]\n",
      "TesT Acc : 0.8625\n",
      "Test F1-Score : 0.8070175438596492\n",
      "-----------------------------------------------------------------------\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "\n",
    "for n in n_tree:\n",
    "    for l in l_rate:\n",
    "        for m in m_depth:\n",
    "            for L1 in L1_norm:\n",
    "\n",
    "                print(\">>> {} <<<\".format(cnt))\n",
    "                cnt +=1\n",
    "                print(\"n_estimators : {}, learning_rate : {}, max_depth : {}, reg_alpha : {}\".format(n, l, m, L1))\n",
    "                model = LGBMClassifier(n_estimators=n, learning_rate=l,\n",
    "                                       max_depth=m, reg_alpha=L1,\n",
    "                                       n_jobs=-1, objective='cross_entropy')\n",
    "                model.fit(X.iloc[train_idx], y.iloc[train_idx])\n",
    "\n",
    "\n",
    "                # Train Acc\n",
    "                y_pred_train = model.predict(X.iloc[train_idx])\n",
    "                cm_train = confusion_matrix(y.iloc[train_idx], y_pred_train)\n",
    "                print(\"Train Confusion Matrix\")\n",
    "                print(cm_train)\n",
    "                print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "                print(\"Train F1-Score : {}\".format(f1_score(y.iloc[train_idx], y_pred_train)))\n",
    "\n",
    "                # Test Acc\n",
    "                y_pred_test = model.predict(X.iloc[valid_idx])\n",
    "                cm_test = confusion_matrix(y.iloc[valid_idx], y_pred_test)\n",
    "                print(\"Test Confusion Matrix\")\n",
    "                print(cm_test)\n",
    "                print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "                print(\"Test F1-Score : {}\".format(f1_score(y.iloc[valid_idx], y_pred_test)))\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                print(\"-----------------------------------------------------------------------\")\n",
    "                save_n.append(n)\n",
    "                save_l.append(l)\n",
    "                save_m.append(m)\n",
    "                save_L1.append(L1)\n",
    "                f1_score_.append(f1_score(y.iloc[valid_idx], y_pred_test))\n",
    "\n",
    "\n",
    "                #joblib.dump(model, './LightGBM_model/Result_{}_{}_{}_{}_{}.pkl'.format(n, l, m, L1, round(save_acc[-1], 4)))\n",
    "                #gc.collect()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> 7 <<<\n",
      "Best Test f1-score : 0.8672566371681417\n",
      "Best n_estimators : 5\n",
      "Best Learning Rate : 0.3\n",
      "Best Max_depth : 3\n",
      "Best L1-norm : 0.3\n"
     ]
    }
   ],
   "source": [
    "print(f\">>> {np.argmax(f1_score_)} <<<\\nBest Test f1-score : {f1_score_[np.argmax(f1_score_)]}\\nBest n_estimators : {save_n[np.argmax(f1_score_)]}\\nBest Learning Rate : {save_l[np.argmax(f1_score_)]}\\nBest Max_depth : {save_m[np.argmax(f1_score_)]}\\nBest L1-norm : {save_L1[np.argmax(f1_score_)]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "LGBMClassifier(learning_rate=0.3, max_depth=3, n_estimators=5,\n               objective='cross_entropy', random_state=119, reg_alpha=0.3)",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(learning_rate=0.3, max_depth=3, n_estimators=5,\n               objective=&#x27;cross_entropy&#x27;, random_state=119, reg_alpha=0.3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(learning_rate=0.3, max_depth=3, n_estimators=5,\n               objective=&#x27;cross_entropy&#x27;, random_state=119, reg_alpha=0.3)</pre></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = LGBMClassifier(n_estimators=save_n[np.argmax(f1_score_)], learning_rate=save_l[np.argmax(f1_score_)],\n",
    "                           max_depth=save_m[np.argmax(f1_score_)], reg_alpha=save_L1[np.argmax(f1_score_)], objective='cross_entropy',\n",
    "                           random_state=119)\n",
    "best_model.fit(X.iloc[train_idx], y.iloc[train_idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Confusion Matrix\n",
      "[[228  13]\n",
      " [ 19 112]]\n",
      "Train Acc : 0.9139784946236559\n",
      "Train F1-Score : 0.875\n"
     ]
    }
   ],
   "source": [
    "# Train Acc\n",
    "y_pre_train = best_model.predict(X.iloc[train_idx])\n",
    "cm_train = confusion_matrix(y.iloc[train_idx], y_pre_train)\n",
    "print(\"Train Confusion Matrix\")\n",
    "print(cm_train)\n",
    "print(\"Train Acc : {}\".format((cm_train[0,0] + cm_train[1,1])/cm_train.sum()))\n",
    "print(\"Train F1-Score : {}\".format(f1_score(y.iloc[train_idx], y_pre_train)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Confusion Matrix\n",
      "[[96 14]\n",
      " [ 1 49]]\n",
      "TesT Acc : 0.90625\n",
      "Test F1-Score : 0.8672566371681417\n"
     ]
    }
   ],
   "source": [
    "# Test Acc\n",
    "y_pre_test = best_model.predict(X.iloc[valid_idx])\n",
    "cm_test = confusion_matrix(y.iloc[valid_idx], y_pre_test)\n",
    "print(\"Test Confusion Matrix\")\n",
    "print(cm_test)\n",
    "print(\"TesT Acc : {}\".format((cm_test[0,0] + cm_test[1,1])/cm_test.sum()))\n",
    "print(\"Test F1-Score : {}\".format(f1_score(y.iloc[valid_idx], y_pre_test)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Score  Feature\n",
      "0      10    event\n",
      "1       4    cd496\n",
      "2       4    cd420\n",
      "3       4     cd40\n",
      "4       3  preanti\n",
      "5       2     wtkg\n",
      "6       2     race\n",
      "7       1      z30\n",
      "8       1      age\n",
      "9       0  symptom\n",
      "10      0    strat\n",
      "11      0     str2\n",
      "12      0        r\n",
      "13      0   oprior\n",
      "14      0   karnof\n",
      "15      0     homo\n",
      "16      0     hemo\n",
      "17      0   gender\n",
      "18      0    drugs\n",
      "19      0    cd820\n",
      "20      0     cd80\n"
     ]
    }
   ],
   "source": [
    "feature_map = pd.DataFrame(sorted(zip(best_model.feature_importances_, X.columns), reverse=True), columns=['Score', 'Feature'])\n",
    "print(feature_map)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 2000x1000 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Importance Score Top 10\n",
    "feature_map_10 = feature_map.iloc[:10]\n",
    "plt.figure(figsize=(20, 10))\n",
    "sns.barplot(x=\"Score\", y=\"Feature\", data=feature_map_10.sort_values(by=\"Score\", ascending=False), errwidth=40)\n",
    "plt.title('XGBoost Importance Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}