{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 11 Regularized Model-ElasticNet 실습\n",
    "\n",
    "## [목적]\n",
    "### 1. ElasticeNet\n",
    "* Regularized Linear Model을 활용하여 Overfitting을 방지함\n",
    "* Hyperparameter lambda를 튜닝할 때 for loop와 GridsearchCV를 활용\n",
    "### 2. Regularized Linear Models의 경우 X's scaling을 필수적으로 진행해야함\n",
    "## [Process]\n",
    "### 1. Define X's &y\n",
    "### 2. Split Train & Valid dataset\n",
    "### 3. Modeling\n",
    "### 4. Model 해석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet, ElasticNetCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.datasets import load_diabetes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import scipy\n",
    "from sklearn import metrics\n",
    "\n",
    "def sse(clf, X, y):\n",
    "    \"\"\"Calculate the standard squared error of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The standard squared error of the model.\n",
    "    \"\"\"\n",
    "    y_hat = clf.predict(X)\n",
    "    sse = np.sum((y_hat - y) ** 2)\n",
    "    return sse / X.shape[0]\n",
    "\n",
    "\n",
    "def adj_r2_score(clf, X, y):\n",
    "    \"\"\"Calculate the adjusted :math:`R^2` of the model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The adjusted :math:`R^2` of the model.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]  # Number of observations\n",
    "    p = X.shape[1]  # Number of features\n",
    "    r_squared = metrics.r2_score(y, clf.predict(X))\n",
    "    return 1 - (1 - r_squared) * ((n - 1) / (n - p - 1))\n",
    "\n",
    "\n",
    "def coef_se(clf, X, y):\n",
    "    \"\"\"Calculate standard error for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of standard errors for the beta coefficients.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    X1 = np.hstack((np.ones((n, 1)), np.matrix(X)))\n",
    "    se_matrix = scipy.linalg.sqrtm(\n",
    "        metrics.mean_squared_error(y, clf.predict(X)) *\n",
    "        np.linalg.inv(X1.T * X1)\n",
    "    )\n",
    "    return np.diagonal(se_matrix)\n",
    "\n",
    "\n",
    "def coef_tval(clf, X, y):\n",
    "    \"\"\"Calculate t-statistic for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of t-statistic values.\n",
    "    \"\"\"\n",
    "    a = np.array(clf.intercept_ / coef_se(clf, X, y)[0])\n",
    "    b = np.array(clf.coef_ / coef_se(clf, X, y)[1:])\n",
    "    return np.append(a, b)\n",
    "\n",
    "\n",
    "def coef_pval(clf, X, y):\n",
    "    \"\"\"Calculate p-values for beta coefficients.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        An array of p-values.\n",
    "    \"\"\"\n",
    "    n = X.shape[0]\n",
    "    t = coef_tval(clf, X, y)\n",
    "    p = 2 * (1 - scipy.stats.t.cdf(abs(t), n - 1))\n",
    "    return p\n",
    "\n",
    "def summary(clf, X, y, xlabels=None):\n",
    "    \"\"\"\n",
    "    Output summary statistics for a fitted regression model.\n",
    "    Parameters\n",
    "    ----------\n",
    "    clf : sklearn.linear_model\n",
    "        A scikit-learn linear model classifier with a `predict()` method.\n",
    "    X : numpy.ndarray\n",
    "        Training data used to fit the classifier.\n",
    "    y : numpy.ndarray\n",
    "        Target training values, of shape = [n_samples].\n",
    "    xlabels : list, tuple\n",
    "        The labels for the predictors.\n",
    "    \"\"\"\n",
    "    # Check and/or make xlabels\n",
    "    ncols = X.shape[1]\n",
    "    if xlabels is None:\n",
    "        xlabels = np.array(\n",
    "            ['x{0}'.format(i) for i in range(1, ncols + 1)], dtype='str')\n",
    "    elif isinstance(xlabels, (tuple, list)):\n",
    "        xlabels = np.array(xlabels, dtype='str')\n",
    "    # Make sure dims of xlabels matches dims of X\n",
    "    if xlabels.shape[0] != ncols:\n",
    "        raise AssertionError(\n",
    "            \"Dimension of xlabels {0} does not match \"\n",
    "            \"X {1}.\".format(xlabels.shape, X.shape))\n",
    "    # Create data frame of coefficient estimates and associated stats\n",
    "    coef_df = pd.DataFrame(\n",
    "        index=['_intercept'] + list(xlabels),\n",
    "        columns=['Estimate', 'Std. Error', 't value', 'p value']\n",
    "    )\n",
    "    try:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (np.round(np.array([clf.intercept_]), 6), np.round((clf.coef_), 6)))\n",
    "    except Exception as e:\n",
    "        coef_df['Estimate'] = np.concatenate(\n",
    "            (\n",
    "                np.round(np.array([clf.intercept_]), 6),\n",
    "                np.round((clf.coef_), 6)\n",
    "            ), axis = 1\n",
    "    )[0,:]\n",
    "    coef_df['Std. Error'] = np.round(coef_se(clf, X, y), 6)\n",
    "    coef_df['t value'] = np.round(coef_tval(clf, X, y), 4)\n",
    "    coef_df['p value'] = np.round(coef_pval(clf, X, y), 6)\n",
    "    # Output results\n",
    "    print('Coefficients:')\n",
    "    print(coef_df.to_string(index=True))\n",
    "    print('---')\n",
    "    print('R-squared:  {0:.6f},    Adjusted R-squared:  {1:.6f},    MSE: {2:.1f}'.format(\n",
    "        metrics.r2_score(y, clf.predict(X)), adj_r2_score(clf, X, y), sse(clf, X, y)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 442 entries, 0 to 441\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AGE     442 non-null    int64  \n",
      " 1   SEX     442 non-null    int64  \n",
      " 2   BMI     442 non-null    float64\n",
      " 3   BP      442 non-null    float64\n",
      " 4   S1      442 non-null    int64  \n",
      " 5   S2      442 non-null    float64\n",
      " 6   S3      442 non-null    float64\n",
      " 7   S4      442 non-null    float64\n",
      " 8   S5      442 non-null    float64\n",
      " 9   S6      442 non-null    int64  \n",
      " 10  Y       442 non-null    int64  \n",
      "dtypes: float64(6), int64(5)\n",
      "memory usage: 38.1 KB\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "data_df = pd.read_csv('https://www4.stat.ncsu.edu/~boos/var.select/diabetes.tab.txt', sep='\\t')\n",
    "data_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "   AGE   BMI     BP   S1     S2    S3   S4      S5  S6  SEX_1  SEX_2\n0   59  32.1  101.0  157   93.2  38.0  4.0  4.8598  87      0      1\n1   48  21.6   87.0  183  103.2  70.0  3.0  3.8918  69      1      0\n2   72  30.5   93.0  156   93.6  41.0  4.0  4.6728  85      0      1\n3   24  25.3   84.0  198  131.4  40.0  5.0  4.8903  89      1      0\n4   50  23.0  101.0  192  125.4  52.0  4.0  4.2905  80      1      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>SEX_1</th>\n      <th>SEX_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>59</td>\n      <td>32.1</td>\n      <td>101.0</td>\n      <td>157</td>\n      <td>93.2</td>\n      <td>38.0</td>\n      <td>4.0</td>\n      <td>4.8598</td>\n      <td>87</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>48</td>\n      <td>21.6</td>\n      <td>87.0</td>\n      <td>183</td>\n      <td>103.2</td>\n      <td>70.0</td>\n      <td>3.0</td>\n      <td>3.8918</td>\n      <td>69</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>72</td>\n      <td>30.5</td>\n      <td>93.0</td>\n      <td>156</td>\n      <td>93.6</td>\n      <td>41.0</td>\n      <td>4.0</td>\n      <td>4.6728</td>\n      <td>85</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>24</td>\n      <td>25.3</td>\n      <td>84.0</td>\n      <td>198</td>\n      <td>131.4</td>\n      <td>40.0</td>\n      <td>5.0</td>\n      <td>4.8903</td>\n      <td>89</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>50</td>\n      <td>23.0</td>\n      <td>101.0</td>\n      <td>192</td>\n      <td>125.4</td>\n      <td>52.0</td>\n      <td>4.0</td>\n      <td>4.2905</td>\n      <td>80</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data_df['Y']\n",
    "X = data_df.drop(columns=['Y'])\n",
    "X = pd.get_dummies(X, columns=['SEX'])\n",
    "X.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 133\n"
     ]
    }
   ],
   "source": [
    "idx = list(range(X.shape[0]))\n",
    "train_idx, valid_idx = train_test_split(idx, test_size=0.3, random_state=2023)\n",
    "print(len(train_idx), len(valid_idx))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "        AGE       BMI        BP        S1        S2        S3        S4  \\\n0  0.666667  0.573840  0.565217  0.294118  0.297578  0.197368  0.318471   \n1  0.483333  0.130802  0.362319  0.421569  0.355248  0.618421  0.159236   \n2  0.883333  0.506329  0.449275  0.289216  0.299885  0.236842  0.318471   \n3  0.083333  0.286920  0.318841  0.495098  0.517878  0.223684  0.477707   \n4  0.516667  0.189873  0.565217  0.465686  0.483276  0.381579  0.318471   \n\n         S5        S6  SEX_1  SEX_2  \n0  0.562217  0.439394    0.0    1.0  \n1  0.222437  0.166667    1.0    0.0  \n2  0.496578  0.409091    0.0    1.0  \n3  0.572923  0.469697    1.0    0.0  \n4  0.362385  0.333333    1.0    0.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AGE</th>\n      <th>BMI</th>\n      <th>BP</th>\n      <th>S1</th>\n      <th>S2</th>\n      <th>S3</th>\n      <th>S4</th>\n      <th>S5</th>\n      <th>S6</th>\n      <th>SEX_1</th>\n      <th>SEX_2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.666667</td>\n      <td>0.573840</td>\n      <td>0.565217</td>\n      <td>0.294118</td>\n      <td>0.297578</td>\n      <td>0.197368</td>\n      <td>0.318471</td>\n      <td>0.562217</td>\n      <td>0.439394</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.483333</td>\n      <td>0.130802</td>\n      <td>0.362319</td>\n      <td>0.421569</td>\n      <td>0.355248</td>\n      <td>0.618421</td>\n      <td>0.159236</td>\n      <td>0.222437</td>\n      <td>0.166667</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.883333</td>\n      <td>0.506329</td>\n      <td>0.449275</td>\n      <td>0.289216</td>\n      <td>0.299885</td>\n      <td>0.236842</td>\n      <td>0.318471</td>\n      <td>0.496578</td>\n      <td>0.409091</td>\n      <td>0.0</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.083333</td>\n      <td>0.286920</td>\n      <td>0.318841</td>\n      <td>0.495098</td>\n      <td>0.517878</td>\n      <td>0.223684</td>\n      <td>0.477707</td>\n      <td>0.572923</td>\n      <td>0.469697</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.516667</td>\n      <td>0.189873</td>\n      <td>0.565217</td>\n      <td>0.465686</td>\n      <td>0.483276</td>\n      <td>0.381579</td>\n      <td>0.318471</td>\n      <td>0.362385</td>\n      <td>0.333333</td>\n      <td>1.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler().fit(X.iloc[train_idx]) # train data로만 훈련\n",
    "X_scal = scaler.transform(X)\n",
    "X_scal = pd.DataFrame(X_scal, columns=X.columns)\n",
    "X_scal.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [ElasticNet Regression]\n",
    "* Hyperparameter Tuning using for Loop\n",
    "* Hyperparameter Tuning using GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## [ElasticeNet Regression Parameters]\n",
    "  - Package : https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html\n",
    "  - alpha : L2-norm Penalty Term\n",
    "    - alpha : 0 일 때, Just Linear Regression\n",
    "  - l1_ratio : L1-norm Penalty Term\n",
    "    - 0 <= l1_ratio <= 1\n",
    "    - l1_ratio : 1 일 때, Just Ridge Regression\n",
    "  - fit_intercept : Centering to zero\n",
    "    - 베타0를 0로 보내는 것 (베타0는 상수이기 때문에)\n",
    "  - max_iter : Maximum number of interation\n",
    "    - Loss Function의 LASSO Penalty Term은 절대 값이기 때문에 Gradient Descent와 같은 최적화가 필요함\n",
    "  - Penalty Term\n",
    "    - 1 / (2 * n_samples) * ||y - Xw||^2_2 + <u>alpha * l1_ratio * ||w||_1</u> + <u>0.5 * alpha * (1 - l1_ratio) * ||w||^2_2</u>"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "penalty = [0.00001, 0.00005, 0.0001, 0.001, 0.01, 0.02, 0.05, 0.1, 0.3, 0.5, 0.7, 1, 5, 10]\n",
    "l1_ratio = [0.9, 0.7, 0.5, 0.3, 0.1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0000100, R2: 0.5302256, MSE: 3084.2148395, RMSE: 55.5357078\n",
      "Alpha: 0.0000100, R2: 0.5302256, MSE: 3084.2148395, RMSE: 55.5357078\n",
      "Alpha: 0.0000100, R2: 0.5302256, MSE: 3084.2148395, RMSE: 55.5357078\n",
      "Alpha: 0.0000100, R2: 0.5302256, MSE: 3084.2148395, RMSE: 55.5357078\n",
      "Alpha: 0.0000100, R2: 0.5302256, MSE: 3084.2148395, RMSE: 55.5357078\n",
      "Alpha: 0.0000500, R2: 0.5304135, MSE: 3082.9815630, RMSE: 55.5246032\n",
      "Alpha: 0.0000500, R2: 0.5304135, MSE: 3082.9815630, RMSE: 55.5246032\n",
      "Alpha: 0.0000500, R2: 0.5304135, MSE: 3082.9815630, RMSE: 55.5246032\n",
      "Alpha: 0.0000500, R2: 0.5304135, MSE: 3082.9815630, RMSE: 55.5246032\n",
      "Alpha: 0.0000500, R2: 0.5304135, MSE: 3082.9815630, RMSE: 55.5246032\n",
      "Alpha: 0.0001000, R2: 0.5305586, MSE: 3082.0291476, RMSE: 55.5160260\n",
      "Alpha: 0.0001000, R2: 0.5305586, MSE: 3082.0291476, RMSE: 55.5160260\n",
      "Alpha: 0.0001000, R2: 0.5305586, MSE: 3082.0291476, RMSE: 55.5160260\n",
      "Alpha: 0.0001000, R2: 0.5305586, MSE: 3082.0291476, RMSE: 55.5160260\n",
      "Alpha: 0.0001000, R2: 0.5305586, MSE: 3082.0291476, RMSE: 55.5160260\n",
      "Alpha: 0.0010000, R2: 0.5301610, MSE: 3084.6392459, RMSE: 55.5395287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.878e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.803e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\dukim\\miniconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:628: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.689e+05, tolerance: 1.732e+02\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha: 0.0010000, R2: 0.5301610, MSE: 3084.6392459, RMSE: 55.5395287\n",
      "Alpha: 0.0010000, R2: 0.5301610, MSE: 3084.6392459, RMSE: 55.5395287\n",
      "Alpha: 0.0010000, R2: 0.5301610, MSE: 3084.6392459, RMSE: 55.5395287\n",
      "Alpha: 0.0010000, R2: 0.5301610, MSE: 3084.6392459, RMSE: 55.5395287\n",
      "Alpha: 0.0100000, R2: 0.5218304, MSE: 3139.3320523, RMSE: 56.0297426\n",
      "Alpha: 0.0100000, R2: 0.5218304, MSE: 3139.3320523, RMSE: 56.0297426\n",
      "Alpha: 0.0100000, R2: 0.5218304, MSE: 3139.3320523, RMSE: 56.0297426\n",
      "Alpha: 0.0100000, R2: 0.5218304, MSE: 3139.3320523, RMSE: 56.0297426\n",
      "Alpha: 0.0100000, R2: 0.5218304, MSE: 3139.3320523, RMSE: 56.0297426\n",
      "Alpha: 0.0200000, R2: 0.5092512, MSE: 3221.9186668, RMSE: 56.7619473\n",
      "Alpha: 0.0200000, R2: 0.5092512, MSE: 3221.9186668, RMSE: 56.7619473\n",
      "Alpha: 0.0200000, R2: 0.5092512, MSE: 3221.9186668, RMSE: 56.7619473\n",
      "Alpha: 0.0200000, R2: 0.5092512, MSE: 3221.9186668, RMSE: 56.7619473\n",
      "Alpha: 0.0200000, R2: 0.5092512, MSE: 3221.9186668, RMSE: 56.7619473\n",
      "Alpha: 0.0500000, R2: 0.4684468, MSE: 3489.8124002, RMSE: 59.0746342\n",
      "Alpha: 0.0500000, R2: 0.4684468, MSE: 3489.8124002, RMSE: 59.0746342\n",
      "Alpha: 0.0500000, R2: 0.4684468, MSE: 3489.8124002, RMSE: 59.0746342\n",
      "Alpha: 0.0500000, R2: 0.4684468, MSE: 3489.8124002, RMSE: 59.0746342\n",
      "Alpha: 0.0500000, R2: 0.4684468, MSE: 3489.8124002, RMSE: 59.0746342\n",
      "Alpha: 0.1000000, R2: 0.4089784, MSE: 3880.2406238, RMSE: 62.2915775\n",
      "Alpha: 0.1000000, R2: 0.4089784, MSE: 3880.2406238, RMSE: 62.2915775\n",
      "Alpha: 0.1000000, R2: 0.4089784, MSE: 3880.2406238, RMSE: 62.2915775\n",
      "Alpha: 0.1000000, R2: 0.4089784, MSE: 3880.2406238, RMSE: 62.2915775\n",
      "Alpha: 0.1000000, R2: 0.4089784, MSE: 3880.2406238, RMSE: 62.2915775\n",
      "Alpha: 0.3000000, R2: 0.2617476, MSE: 4846.8570798, RMSE: 69.6193729\n",
      "Alpha: 0.3000000, R2: 0.2617476, MSE: 4846.8570798, RMSE: 69.6193729\n",
      "Alpha: 0.3000000, R2: 0.2617476, MSE: 4846.8570798, RMSE: 69.6193729\n",
      "Alpha: 0.3000000, R2: 0.2617476, MSE: 4846.8570798, RMSE: 69.6193729\n",
      "Alpha: 0.3000000, R2: 0.2617476, MSE: 4846.8570798, RMSE: 69.6193729\n",
      "Alpha: 0.5000000, R2: 0.1888377, MSE: 5325.5326941, RMSE: 72.9762475\n",
      "Alpha: 0.5000000, R2: 0.1888377, MSE: 5325.5326941, RMSE: 72.9762475\n",
      "Alpha: 0.5000000, R2: 0.1888377, MSE: 5325.5326941, RMSE: 72.9762475\n",
      "Alpha: 0.5000000, R2: 0.1888377, MSE: 5325.5326941, RMSE: 72.9762475\n",
      "Alpha: 0.5000000, R2: 0.1888377, MSE: 5325.5326941, RMSE: 72.9762475\n",
      "Alpha: 0.7000000, R2: 0.1437170, MSE: 5621.7643504, RMSE: 74.9784259\n",
      "Alpha: 0.7000000, R2: 0.1437170, MSE: 5621.7643504, RMSE: 74.9784259\n",
      "Alpha: 0.7000000, R2: 0.1437170, MSE: 5621.7643504, RMSE: 74.9784259\n",
      "Alpha: 0.7000000, R2: 0.1437170, MSE: 5621.7643504, RMSE: 74.9784259\n",
      "Alpha: 0.7000000, R2: 0.1437170, MSE: 5621.7643504, RMSE: 74.9784259\n",
      "Alpha: 1.0000000, R2: 0.1019201, MSE: 5896.1740379, RMSE: 76.7865485\n",
      "Alpha: 1.0000000, R2: 0.1019201, MSE: 5896.1740379, RMSE: 76.7865485\n",
      "Alpha: 1.0000000, R2: 0.1019201, MSE: 5896.1740379, RMSE: 76.7865485\n",
      "Alpha: 1.0000000, R2: 0.1019201, MSE: 5896.1740379, RMSE: 76.7865485\n",
      "Alpha: 1.0000000, R2: 0.1019201, MSE: 5896.1740379, RMSE: 76.7865485\n",
      "Alpha: 5.0000000, R2: -0.0045180, MSE: 6594.9729743, RMSE: 81.2094389\n",
      "Alpha: 5.0000000, R2: -0.0045180, MSE: 6594.9729743, RMSE: 81.2094389\n",
      "Alpha: 5.0000000, R2: -0.0045180, MSE: 6594.9729743, RMSE: 81.2094389\n",
      "Alpha: 5.0000000, R2: -0.0045180, MSE: 6594.9729743, RMSE: 81.2094389\n",
      "Alpha: 5.0000000, R2: -0.0045180, MSE: 6594.9729743, RMSE: 81.2094389\n",
      "Alpha: 10.0000000, R2: -0.0211259, MSE: 6704.0090923, RMSE: 81.8780135\n",
      "Alpha: 10.0000000, R2: -0.0211259, MSE: 6704.0090923, RMSE: 81.8780135\n",
      "Alpha: 10.0000000, R2: -0.0211259, MSE: 6704.0090923, RMSE: 81.8780135\n",
      "Alpha: 10.0000000, R2: -0.0211259, MSE: 6704.0090923, RMSE: 81.8780135\n",
      "Alpha: 10.0000000, R2: -0.0211259, MSE: 6704.0090923, RMSE: 81.8780135\n"
     ]
    }
   ],
   "source": [
    "for p in penalty:\n",
    "    for r in l1_ratio:\n",
    "        model = ElasticNet(alpha=p).fit(X_scal.iloc[train_idx], y.iloc[train_idx])\n",
    "        score = model.score(X_scal.iloc[valid_idx], y.iloc[valid_idx])\n",
    "        pred_y = model.predict(X_scal.iloc[valid_idx])\n",
    "        mse = mean_squared_error(y.iloc[valid_idx], pred_y)\n",
    "        print(f\"Alpha: {p:.7f}, R2: {score:.7f}, MSE: {mse:.7f}, RMSE: {np.sqrt(mse):.7f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "              Estimate    Std. Error  t value   p value\n",
      "_intercept   48.093201  3.887779e+08   0.0000  1.000000\n",
      "AGE          -5.356582  2.437852e+01  -0.2197  0.826424\n",
      "BMI         105.941275  3.250571e+01   3.2592  0.001421\n",
      "BP           61.583874  2.889356e+01   2.1314  0.034909\n",
      "S1           -6.957002  1.673428e+02  -0.0416  0.966902\n",
      "S2          -11.267900  1.186959e+02  -0.0949  0.924514\n",
      "S3          -49.678169  7.217783e+01  -0.6883  0.492488\n",
      "S4           28.961671  5.812461e+01   0.4983  0.619124\n",
      "S5           94.632519  5.116358e+01   1.8496  0.066607\n",
      "S6           27.025748  3.479475e+01   0.7767  0.438714\n",
      "SEX_1         9.756084  3.887779e+08   0.0000  1.000000\n",
      "SEX_2        -9.517310  3.887779e+08  -0.0000  1.000000\n",
      "---\n",
      "R-squared:  0.509251,    Adjusted R-squared:  0.464638,    MSE: 3221.9\n"
     ]
    }
   ],
   "source": [
    "model_best = ElasticNet(alpha=0.02).fit(X_scal.iloc[train_idx], y.iloc[train_idx])\n",
    "summary(model_best, X_scal.iloc[valid_idx], y.iloc[valid_idx], xlabels=X.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# using ElasticNetCV\n",
    "grid = dict()\n",
    "grid['alpha'] = penalty\n",
    "grid['l1_ratio'] = l1_ratio"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 56.8906\n",
      "Config: {'alpha': 0.01, 'l1_ratio': 0.3}\n"
     ]
    }
   ],
   "source": [
    "# define model\n",
    "model = ElasticNet()\n",
    "# define search\n",
    "search = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n",
    "# perform the search\n",
    "results = search.fit(X_scal.iloc[valid_idx], y.iloc[valid_idx])\n",
    "# summarize\n",
    "print('RMSE: {:.4f}'.format(-results.best_score_))\n",
    "print('Config: {}'.format(results.best_params_))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha:0.0100000, l1_ratio: 0.3000000, R2:0.5171797, MSE:3169.8655476, RMSE:56.3015590\n",
      "Coefficients:\n",
      "              Estimate    Std. Error  t value   p value\n",
      "_intercept   45.921027  3.856246e+08   0.0000  1.000000\n",
      "AGE          -7.326230  2.367229e+01  -0.3095  0.757440\n",
      "BMI         112.053983  3.220196e+01   3.4797  0.000681\n",
      "BP           63.835355  2.851909e+01   2.2383  0.026874\n",
      "S1          -10.286770  1.658942e+02  -0.0620  0.950650\n",
      "S2          -11.664902  1.176090e+02  -0.0992  0.921143\n",
      "S3          -51.885195  7.142718e+01  -0.7264  0.468875\n",
      "S4           26.375923  5.759678e+01   0.4579  0.647748\n",
      "S5          102.402575  5.065198e+01   2.0217  0.045230\n",
      "S6           25.791145  3.430041e+01   0.7519  0.453438\n",
      "SEX_1        10.231459  3.856246e+08   0.0000  1.000000\n",
      "SEX_2        -9.855686  3.856246e+08  -0.0000  1.000000\n",
      "---\n",
      "R-squared:  0.517180,    Adjusted R-squared:  0.473287,    MSE: 3169.9\n"
     ]
    }
   ],
   "source": [
    "model_best = ElasticNet(alpha=results.best_params_['alpha'],\n",
    "                        l1_ratio=results.best_params_['l1_ratio']).fit(X_scal.iloc[train_idx], y.iloc[train_idx])\n",
    "score = model_best.score(X_scal.iloc[valid_idx], y.iloc[valid_idx])\n",
    "pred_y = model_best.predict(X_scal.iloc[valid_idx])\n",
    "mse = mean_squared_error(y.iloc[valid_idx], pred_y)\n",
    "print(\"Alpha:{0:.7f}, l1_ratio: {1:.7f}, R2:{2:.7f}, MSE:{3:.7f}, RMSE:{4:.7f}\".format(results.best_params_['alpha'],\n",
    "                                                                                   results.best_params_['l1_ratio'],\n",
    "                                                                                   score, mse, np.sqrt(mse)))\n",
    "summary(model_best, X_scal.iloc[valid_idx], y.iloc[valid_idx], xlabels=X.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# BMI, S3, S5 만 LinearRegression 적용\n",
    "target_column = ['BMI', 'BP', 'S3', 'S5', 'S6']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "results = LinearRegression().fit(X.iloc[train_idx][target_column], y.iloc[train_idx])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients:\n",
      "              Estimate  Std. Error  t value   p value\n",
      "_intercept -244.912511   71.117961  -3.4438  0.000769\n",
      "BMI           5.685139    1.257908   4.5195  0.000014\n",
      "BP            0.724639    0.302647   2.3943  0.018056\n",
      "S3           -0.668388    0.315558  -2.1181  0.036040\n",
      "S5           44.553518   10.867197   4.0998  0.000072\n",
      "S6            0.072288    0.328272   0.2202  0.826051\n",
      "---\n",
      "R-squared:  0.504894,    Adjusted R-squared:  0.485402,    MSE: 3250.5\n"
     ]
    }
   ],
   "source": [
    "summary(results, X.iloc[valid_idx][target_column], y.loc[valid_idx], xlabels=target_column)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}